{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Introduction to Spark In-memmory Computing via Python PySpark </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Spark is an implementation of the MapReduce programming paradigm that operates on in-memory data and allows data reuses across multiple computations.\n",
    "- Performance of Spark is significantly better than its predecessor, Hadoop MapReduce. \n",
    "- Spark's primary data abstraction is Resilient Distributed Dataset (RDD):\n",
    "    - Read-only, partitioned collection of records\n",
    "    - Created (aka written) through deterministic operations on data:\n",
    "        - Loading from stable storage\n",
    "        - Transforming from other RDDs\n",
    "        - Generating through coarse-grained operations such as map, join, filter ...\n",
    "    - Do not need to be materialized at all time and are recoverable via **data lineage**\n",
    "\n",
    "<img src=\"figures/spark2_arch.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Host:  node1965.palmetto.clemson.edu\n",
      "Slaves: \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "def generate_slaves_file(node_file=os.environ['PBS_NODEFILE'], \n",
    "                         slaves_file='./spark-2.1.0-bin-hadoop2.7/conf/slaves'):\n",
    "    node_list = subprocess.check_output(['cat', node_file]).decode(\"utf-8\").strip().split('\\n')\n",
    "    node_list = sorted(list(set(node_list)))\n",
    "    print(\"Host: \", node_list[0])\n",
    "    print(\"Slaves: \") \n",
    "    with open(slaves_file, 'w') as slave_file_fp:\n",
    "        for node in node_list[1:]:\n",
    "            slave_file_fp.write('{}\\n'.format(node))\n",
    "            print(\"\\t\", node)\n",
    "generate_slaves_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!more spark-2.1.0-bin-hadoop2.7/conf/slaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Permanently added 'node1965,10.125.10.88' (RSA) to the list of known hosts.\n",
      "starting org.apache.spark.deploy.master.Master, logging to /home/lngo/intro-to-spark/spark-2.1.0-bin-hadoop2.7/logs/spark-lngo-org.apache.spark.deploy.master.Master-1-node1965.out\n"
     ]
    }
   ],
   "source": [
    "!ssh node1965 '/home/lngo/intro-to-spark/spark-2.1.0-bin-hadoop2.7/sbin/start-all.sh --host node1965'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ssh node1916 '/home/lngo/intro-to-spark/spark-2.1.0-bin-hadoop2.7/sbin/stop-all.sh --host node1916'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting Started\n",
    "\n",
    "Spark stores data in memory. This memory space is represented by variable **sc** (SparkContext). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, './spark-2.1.0-bin-hadoop2.7/python')\n",
    "sys.path.insert(0, './spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip')\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/lngo/intro-to-spark/spark-2.1.0-bin-hadoop2.7/\"\n",
    "os.environ['PYSPARK_PYTHON'] = '/software/anaconda3/4.2.0/bin/python'\n",
    "\n",
    "import pyspark\n",
    "conf = pyspark.SparkConf()\n",
    "conf.setMaster(\"spark://node1916:7077\")\n",
    "conf.set(\"spark.driver.memory\",\"4g\")\n",
    "conf.set(\"spark.executor.memory\",\"60g\")\n",
    "conf.set(\"spark.num.executors\",\"3\")\n",
    "conf.set(\"spark.executor.cores\",\"12\")\n",
    "\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x2ba1e249b1d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textFile = sc.textFile(\"text/gutenberg-shakespeare.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text/gutenberg-shakespeare.txt MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0\n"
     ]
    }
   ],
   "source": [
    "print (textFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What does Spark do with my data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Storage Level:**\n",
    "- Does RDD use disk?\n",
    "- Does RDD use memory?\n",
    "- Does RDD use off-heap memory?\n",
    "- Should an RDD be serialized (while persisting)?\n",
    "- How many replicas (default: 1) to use (can only be less than 40)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(False, False, False, False, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile.getStorageLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text/gutenberg-shakespeare.txt MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(False, True, False, False, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile.getStorageLevel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- By default, each transformed RDD may be recomputed each time you run an action on it.\n",
    "- It is also possible to *persist* RDD in memory using *persist()* or *cache()*\n",
    "    - *persist()* allows you to specify level of storage for RDD\n",
    "    - *cache()* only persists RDD in memory\n",
    "    - To retire RDD from memory, *unpersist()* is called"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. WordCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data operations in Spark are categorized into two groups, *transformation* and *action*. \n",
    "- A *transformation* creates new dataset from existing data. Examples of *transformation* include map, filter, reduceByKey, and sort. \n",
    "- An *action* returns a value to the driver program (aka memory space of this notebook) after running a computation on the data set. Examples of *action* include count, collect, reduce, and save. \n",
    "\n",
    "\"All transformations in Spark are lazy, in that they do not compute their results right away. Instead, they just remember the transformations applied to some base dataset (e.g. a file). The transformations are only computed when an action requires a result to be returned to the driver program.\" -- Spark Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RDD Operations in Spark\n",
    "\n",
    "**Transformations: **\n",
    "\n",
    "- *map*(f: T -> U) : RDD[T] -> RDD[U]\n",
    "- *filter*(f: T -> Bool) : RDD[T] -> RDD[T]\n",
    "- *flatMap*(f: T -> Seq[U]) : RDD[T] -> RDD[U]\n",
    "- *sample*(*fraction*: Float) : RDD[T] -> RDD[T] (deterministic sampling)\n",
    "- *groupByKey*() : RDD[(K,V)] -> RDD[(K, Seq[V])]\n",
    "- *reduceByKey*(f: (V,V) -> V) : RDD[(K,V)] -> RDD[(K,V)]\n",
    "- *union*() : (RDD[T], RDD[T]) -> RDD[T]\n",
    "- *join*() : (RDD[(K,V)], RDD[(K,W)]) -> RDD[(K,(V,W))]\n",
    "- *cogroup*() : (RDD[(K,V)], RDD[(K,W)] -> RDD[(K, (Seq[V],Seq[W]))]\n",
    "- *crossProduct*() : (RDD[T], RDD[U]) -> RDD[(T,U)]\n",
    "- *mapValues*(f: V -> W) : RDD[(K,V)] -> RDD[(K,W)] (preserves partitioning)\n",
    "- *sort*(c: Comparator[K]) :  RDD[(K,V)] -> RDD[(K,V)]\n",
    "- *partitionBy*(p: Partitioner[K]) : RDD[(K,V)] -> RDD[(K,V)]\n",
    "\n",
    "**Actions:**\n",
    "\n",
    "- *count*() : RDD[T] -> Long\n",
    "- *collect*() : RDD[T] -> Seq[T]\n",
    "- *reduce*(f: (T,T) -> T) : RDD[T] -> T\n",
    "- *lookup*(k : K) : RDD[(K,V)] -> Seq[V] (on hash/range partitionied RDDs)\n",
    "- *save*(path: String) : Outputs RDD to a storage system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textFile = sc.textFile(\"text/gutenberg-shakespeare.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text/gutenberg-shakespeare.txt MapPartitionsRDD[3] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 ms, sys: 2 ms, total: 13 ms\n",
      "Wall time: 1.65 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "124213"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "textFile.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordcount = textFile.flatMap(lambda line: line.split(\" \")) \\\n",
    "            .map(lambda word: (word, 1)) \\\n",
    "            .reduceByKey(lambda a, b: a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[9] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordcount.saveAsTextFile(\"output-wordcount-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', 516839)\r\n",
      "('Quince', 1)\r\n",
      "('LIBRARY,', 218)\r\n",
      "('Just', 10)\r\n",
      "('enrooted', 1)\r\n",
      "('divers', 20)\r\n",
      "('Doubtless', 2)\r\n",
      "('undistinguishable,', 1)\r\n",
      "('Rheims,', 1)\r\n",
      "('Freedom!', 1)\r\n",
      "('incorporate.', 1)\r\n",
      "('bawd!', 3)\r\n",
      "('Sir-I', 1)\r\n",
      "('withering', 2)\r\n",
      "('Mopsa,', 1)\r\n",
      "('[BEROWNE', 3)\r\n",
      "('forgetfulness?', 1)\r\n",
      "('Tranio?', 1)\r\n",
      "('Wound', 3)\r\n",
      "('twice,', 2)\r\n"
     ]
    }
   ],
   "source": [
    "!cat output-wordcount-01/part-00000 \\\n",
    "    2>/dev/null | head -n 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step-by-step actions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat text/gutenberg-shakespeare.txt \\\n",
    "    2>/dev/null | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordcount_step_01 = textFile.flatMap(lambda line: line.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordcount_step_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordcount_step_01.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordcount_step_02 = wordcount_step_01.map(lambda word: (word, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordcount_step_02.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordcount_step_03 = wordcount_step_02.reduceByKey(lambda a, b: a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordcount_step_03.take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Movie Ratings\n",
    "\n",
    "An independent movie company is looking to invest in a new movie project. With limited finance, the company wants to \n",
    "analyze the reaction of audiences, particularly toward various movie genres, in order to identify beneficial \n",
    "movie project to focus on. The company relies on data collected from a publicly available recommendation service \n",
    "by [MovieLens](http://dl.acm.org/citation.cfm?id=2827872). This \n",
    "[dataset](http://files.grouplens.org/datasets/movielens/ml-10m-README.html) contains **24404096** ratings and **668953**\n",
    " tag applications across **40110** movies. These data were created by **247753** users between January 09, 1995 and January 29, 2016. This dataset was generated on October 17, 2016. \n",
    "\n",
    "From this dataset, several analyses are possible, include the followings:\n",
    "1.   Find movies which have the highest average ratings over the years and identify the corresponding genre.\n",
    "2.   Find genres which have the highest average ratings over the years.\n",
    "3.   Find users who rate movies most frequently in order to contact them for in-depth marketing analysis.\n",
    "\n",
    "These types of analyses, which are somewhat ambiguous, demand the ability to quickly process large amount of data in \n",
    "elatively short amount of time for decision support purposes. In these situations, the sizes of the data typically \n",
    "make analysis done on a single machine impossible and analysis done using a remote storage system impractical. For \n",
    "remainder of the lessons, we will learn how HDFS provides the basis to store massive amount of data and to enable \n",
    "the programming approach to analyze these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls -h movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat  movielens/README.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat  movielens/links.csv \\\n",
    "    2>/dev/null | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat  movielens/movies.csv \\\n",
    "    2>/dev/null | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat  movielens/ratings.csv \\\n",
    "    2>/dev/null | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat  movielens/tags.csv \\\n",
    "    2>/dev/null | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratings = sc.textFile(\"movielens/ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movielens/ratings.csv MapPartitionsRDD[11] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 ms, sys: 3 ms, total: 12 ms\n",
      "Wall time: 5.67 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24404097"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ratings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 ms, sys: 4 ms, total: 13 ms\n",
      "Wall time: 2.99 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24404097"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ratings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 ms, sys: 3 ms, total: 12 ms\n",
      "Wall time: 3.05 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24404097"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ratings.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Find movies which have the highest average ratings over the years and identify the corresponding genre\n",
    "\n",
    "- Find the average ratings of all movies over the years\n",
    "- Identify the corresponding genres for each movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['userId,movieId,rating,timestamp',\n",
       " '1,122,2.0,945544824',\n",
       " '1,172,1.0,945544871',\n",
       " '1,1221,5.0,945544788',\n",
       " '1,1441,4.0,945544871']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId,movieId,rating,timestamp\n"
     ]
    }
   ],
   "source": [
    "ratingHeader = ratings.first() #extract header\n",
    "print(ratingHeader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratingsOnly = ratings.filter(lambda x:x != ratingHeader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,122,2.0,945544824',\n",
       " '1,172,1.0,945544871',\n",
       " '1,1221,5.0,945544788',\n",
       " '1,1441,4.0,945544871',\n",
       " '1,1609,3.0,945544824']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingsOnly.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movieRatings = ratingsOnly.map(lambda line: (line.split(\",\")[1], float(line.split(\",\")[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('122', 2.0), ('172', 1.0), ('1221', 5.0), ('1441', 4.0), ('1609', 3.0)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieRatings.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Possible approaches in aggregating data:** \n",
    "- groupByKey and mapValues\n",
    "- reduceByKey and countByKey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**groupByKey and mapValues**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('154214', <pyspark.resultiterable.ResultIterable at 0x2ba1e24ad588>),\n",
       " ('27479', <pyspark.resultiterable.ResultIterable at 0x2ba1e24ad710>),\n",
       " ('129667', <pyspark.resultiterable.ResultIterable at 0x2ba1e24adf28>),\n",
       " ('140054', <pyspark.resultiterable.ResultIterable at 0x2ba1e24ad780>),\n",
       " ('45183', <pyspark.resultiterable.ResultIterable at 0x2ba1e24ade10>)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupByKeyRatings = movieRatings.groupByKey()\n",
    "\n",
    "groupByKeyRatings.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('154214', [3.5, 0.5, 2.0]),\n",
       " ('27479', [4.0, 1.5, 1.0]),\n",
       " ('129667', [5.0, 5.0, 2.0, 3.0]),\n",
       " ('140054', [3.5, 2.0, 4.0]),\n",
       " ('45183',\n",
       "  [3.0,\n",
       "   1.5,\n",
       "   3.5,\n",
       "   3.0,\n",
       "   3.0,\n",
       "   2.0,\n",
       "   3.5,\n",
       "   2.0,\n",
       "   1.5,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   3.5,\n",
       "   5.0,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   0.5,\n",
       "   2.0,\n",
       "   4.5,\n",
       "   5.0,\n",
       "   2.0,\n",
       "   4.0,\n",
       "   4.5,\n",
       "   4.0,\n",
       "   5.0,\n",
       "   3.5,\n",
       "   2.0,\n",
       "   3.5,\n",
       "   4.5,\n",
       "   3.5,\n",
       "   0.5,\n",
       "   5.0,\n",
       "   4.5,\n",
       "   3.0,\n",
       "   3.5,\n",
       "   3.5,\n",
       "   4.5,\n",
       "   3.5,\n",
       "   4.5,\n",
       "   4.5,\n",
       "   4.5,\n",
       "   3.5,\n",
       "   5.0,\n",
       "   0.5,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   2.5,\n",
       "   2.5,\n",
       "   2.0,\n",
       "   3.0,\n",
       "   4.5,\n",
       "   3.5,\n",
       "   2.5,\n",
       "   4.0,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   3.0,\n",
       "   2.5,\n",
       "   4.0,\n",
       "   4.5,\n",
       "   4.5,\n",
       "   4.5,\n",
       "   4.5,\n",
       "   4.5,\n",
       "   4.0,\n",
       "   3.5,\n",
       "   3.0,\n",
       "   2.5,\n",
       "   3.5,\n",
       "   4.5,\n",
       "   2.5,\n",
       "   5.0,\n",
       "   3.5,\n",
       "   3.5,\n",
       "   3.0,\n",
       "   2.5,\n",
       "   3.0,\n",
       "   4.5,\n",
       "   2.0,\n",
       "   4.0,\n",
       "   3.5,\n",
       "   3.5,\n",
       "   3.0,\n",
       "   3.5,\n",
       "   3.5,\n",
       "   5.0,\n",
       "   4.5,\n",
       "   3.0,\n",
       "   3.5,\n",
       "   3.0,\n",
       "   3.0,\n",
       "   3.5,\n",
       "   5.0,\n",
       "   5.0,\n",
       "   4.5,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   2.0,\n",
       "   4.5,\n",
       "   3.0,\n",
       "   5.0,\n",
       "   4.0,\n",
       "   3.0,\n",
       "   4.5,\n",
       "   2.5,\n",
       "   4.0,\n",
       "   2.0,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   2.5,\n",
       "   1.0,\n",
       "   3.0,\n",
       "   3.0,\n",
       "   3.5,\n",
       "   5.0,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   3.0,\n",
       "   4.0,\n",
       "   4.5,\n",
       "   4.0,\n",
       "   5.0,\n",
       "   4.0,\n",
       "   3.5,\n",
       "   3.0,\n",
       "   3.0,\n",
       "   4.5,\n",
       "   5.0,\n",
       "   5.0,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   3.5,\n",
       "   2.0,\n",
       "   2.0,\n",
       "   2.5,\n",
       "   3.5,\n",
       "   3.0,\n",
       "   2.0,\n",
       "   5.0,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   3.5,\n",
       "   3.5,\n",
       "   3.5,\n",
       "   5.0,\n",
       "   4.5,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   3.0,\n",
       "   3.5,\n",
       "   4.5,\n",
       "   3.5,\n",
       "   5.0,\n",
       "   4.5,\n",
       "   3.0,\n",
       "   2.0,\n",
       "   4.0,\n",
       "   3.0,\n",
       "   1.0,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   5.0,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   3.0,\n",
       "   3.5,\n",
       "   3.0,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   4.5,\n",
       "   4.5,\n",
       "   4.0,\n",
       "   2.5,\n",
       "   4.0,\n",
       "   3.0,\n",
       "   3.0,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   3.0,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   3.0,\n",
       "   4.0,\n",
       "   4.5,\n",
       "   3.0,\n",
       "   1.0,\n",
       "   4.0,\n",
       "   3.0,\n",
       "   1.0,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   2.0,\n",
       "   4.0,\n",
       "   1.5,\n",
       "   3.5,\n",
       "   3.0,\n",
       "   4.5,\n",
       "   4.0,\n",
       "   1.0,\n",
       "   2.5,\n",
       "   4.5,\n",
       "   4.0,\n",
       "   3.0,\n",
       "   2.5,\n",
       "   3.0,\n",
       "   3.5,\n",
       "   3.0,\n",
       "   3.5,\n",
       "   3.5,\n",
       "   2.5,\n",
       "   3.0,\n",
       "   4.0,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   0.5,\n",
       "   3.5,\n",
       "   3.0,\n",
       "   4.0,\n",
       "   5.0,\n",
       "   3.0,\n",
       "   3.0,\n",
       "   3.5,\n",
       "   2.0,\n",
       "   4.5,\n",
       "   3.5,\n",
       "   4.5,\n",
       "   4.5,\n",
       "   3.5,\n",
       "   4.5,\n",
       "   4.5,\n",
       "   4.0,\n",
       "   2.0,\n",
       "   4.0,\n",
       "   4.5,\n",
       "   4.0,\n",
       "   4.5,\n",
       "   4.0,\n",
       "   2.5,\n",
       "   4.0,\n",
       "   4.5,\n",
       "   3.0,\n",
       "   3.5,\n",
       "   3.0,\n",
       "   1.0,\n",
       "   5.0,\n",
       "   4.5,\n",
       "   2.0,\n",
       "   4.0,\n",
       "   5.0,\n",
       "   2.0,\n",
       "   3.5,\n",
       "   3.5,\n",
       "   3.0,\n",
       "   2.5,\n",
       "   4.5,\n",
       "   4.0,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   0.5,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   3.5,\n",
       "   1.5,\n",
       "   4.0,\n",
       "   4.5,\n",
       "   4.0,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   3.5,\n",
       "   3.5,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   3.5,\n",
       "   3.0,\n",
       "   4.5,\n",
       "   3.5,\n",
       "   2.5,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   5.0,\n",
       "   4.0,\n",
       "   3.0,\n",
       "   3.0,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   3.5,\n",
       "   3.5,\n",
       "   2.0,\n",
       "   3.5,\n",
       "   2.5,\n",
       "   2.0,\n",
       "   4.0,\n",
       "   2.5,\n",
       "   4.5,\n",
       "   3.0,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   3.5,\n",
       "   5.0,\n",
       "   0.5,\n",
       "   4.0,\n",
       "   3.5,\n",
       "   2.5,\n",
       "   4.0,\n",
       "   0.5,\n",
       "   3.5,\n",
       "   5.0,\n",
       "   5.0,\n",
       "   1.5,\n",
       "   4.0,\n",
       "   3.5,\n",
       "   2.0,\n",
       "   5.0,\n",
       "   1.5,\n",
       "   3.5,\n",
       "   5.0,\n",
       "   4.0,\n",
       "   3.5,\n",
       "   3.0,\n",
       "   2.0,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   4.5,\n",
       "   4.5,\n",
       "   3.0,\n",
       "   4.5,\n",
       "   3.0,\n",
       "   2.0,\n",
       "   5.0,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   3.0,\n",
       "   4.0,\n",
       "   3.5,\n",
       "   5.0,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   3.5,\n",
       "   4.5,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   4.5,\n",
       "   5.0,\n",
       "   4.5,\n",
       "   3.5,\n",
       "   3.5,\n",
       "   3.0,\n",
       "   4.0,\n",
       "   3.5,\n",
       "   3.0,\n",
       "   5.0,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   4.5,\n",
       "   4.0,\n",
       "   3.0,\n",
       "   3.0,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   2.5,\n",
       "   3.5,\n",
       "   3.5,\n",
       "   4.5,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   4.5,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   3.0,\n",
       "   5.0,\n",
       "   3.5,\n",
       "   5.0,\n",
       "   5.0,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   5.0,\n",
       "   3.0,\n",
       "   3.0,\n",
       "   5.0,\n",
       "   3.5,\n",
       "   4.5,\n",
       "   3.0,\n",
       "   3.0,\n",
       "   3.5,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   2.0,\n",
       "   4.0,\n",
       "   5.0,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   5.0,\n",
       "   3.5,\n",
       "   5.0,\n",
       "   3.0,\n",
       "   3.0,\n",
       "   4.0,\n",
       "   3.5,\n",
       "   0.5,\n",
       "   5.0,\n",
       "   4.0,\n",
       "   2.5,\n",
       "   3.5,\n",
       "   3.5,\n",
       "   3.0,\n",
       "   3.5,\n",
       "   2.5,\n",
       "   3.0,\n",
       "   2.5,\n",
       "   2.5,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   4.5,\n",
       "   4.0,\n",
       "   5.0])]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapValuesToListRatings = groupByKeyRatings.mapValues(list)\n",
    "\n",
    "mapValuesToListRatings.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('154214', 2.0),\n",
       " ('27479', 2.1666666666666665),\n",
       " ('129667', 3.75),\n",
       " ('140054', 3.1666666666666665),\n",
       " ('45183', 3.5485781990521326)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgRatings01 = mapValuesToListRatings.mapValues(lambda V: sum(V) / float(len(V)))\n",
    "\n",
    "avgRatings01.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(3.5 + 3.5 + 2.5 + 3.5 + 2.0 + 3.5 + 2.5 + 3.0) / 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**reduceByKey and countByKey**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "countsByKey = movieRatings.countByKey()\n",
    "\n",
    "countsByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sumValues(x,y):\n",
    "    return (x + y)\n",
    "\n",
    "sumRatings = movieRatings.reduceByKey(sumValues)\n",
    "\n",
    "sumRatings.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "sumRatings = movieRatings.reduceByKey(operator.add)\n",
    "sumRatings.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avgRatings02 = sumRatings.map(lambda x: (x[0], x[1] / countsByKey.get(x[0])))\n",
    "\n",
    "avgRatings02.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we augment movie ratings data with title informations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies = sc.textFile(\"movielens/movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieId,title,genres\n"
     ]
    }
   ],
   "source": [
    "movieHeader = movies.first() #extract header\n",
    "print(movieHeader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,Toy Story (1995),Adventure|Animation|Children|Comedy|Fantasy',\n",
       " '2,Jumanji (1995),Adventure|Children|Fantasy',\n",
       " '3,Grumpier Old Men (1995),Comedy|Romance',\n",
       " '4,Waiting to Exhale (1995),Comedy|Drama|Romance',\n",
       " '5,Father of the Bride Part II (1995),Comedy']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = movies.filter(lambda x:x != movieHeader)\n",
    "\n",
    "movies.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', ('Toy Story (1995)', 'Adventure|Animation|Children|Comedy|Fantasy')),\n",
       " ('2', ('Jumanji (1995)', 'Adventure|Children|Fantasy')),\n",
       " ('3', ('Grumpier Old Men (1995)', 'Comedy|Romance')),\n",
       " ('4', ('Waiting to Exhale (1995)', 'Comedy|Drama|Romance')),\n",
       " ('5', ('Father of the Bride Part II (1995)', 'Comedy'))]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieInfo = movies.map(lambda line: (line.split(\",\")[0], (line.split(\",\")[1], line.split(\",\")[2])))\n",
    "\n",
    "movieInfo.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1440', (2.776470588235294, ('Amos & Andrew (1993)', 'Comedy'))),\n",
       " ('106450', (4.25, ('Chicago Overcoat (2009)', 'Action|Drama'))),\n",
       " ('564', (2.3294797687861273, ('Chasers (1994)', 'Comedy'))),\n",
       " ('108318', (2.8088235294117645, ('\"Single Shot', ' A (2013)\"'))),\n",
       " ('150421', (3.0, ('Man on Horseback (1969)', '(no genres listed)')))]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmentedRatings = avgRatings01.join(movieInfo)\n",
    "\n",
    "augmentedRatings.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Movie with highest average rating:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('120436', (5.0, ('Garbo Talks (1984)', 'Comedy|Drama'))),\n",
       " ('136874', (5.0, ('Natarang (2010)', '(no genres listed)'))),\n",
       " ('146946', (5.0, ('The Hardy Bucks Movie (2013)', 'Comedy'))),\n",
       " ('114353', (5.0, ('Heavyweights (Schwere Jungs) (2006)', 'Comedy'))),\n",
       " ('123727', (5.0, ('Immigration Tango (2011)', 'Comedy|Romance'))),\n",
       " ('164869', (5.0, ('A Cinderella Story: If the Shoe Fits (2016)', 'Comedy'))),\n",
       " ('159423',\n",
       "  (5.0,\n",
       "   ('Jonas Brothers: The Concert Experience (2009)', '(no genres listed)'))),\n",
       " ('133575', (5.0, ('Do Detectives Think? (1927)', 'Comedy'))),\n",
       " ('93967',\n",
       "  (5.0, ('\"Keeping the Promise (Sign of the Beaver', ' The) (1997)\"'))),\n",
       " ('160325', (5.0, ('I Love Hong Kong (2011)', 'Comedy')))]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmentedRatings.takeOrdered(10, key = lambda x : -x[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Movie with lowest average rating:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('164927', (0.5, ('Where Souls Go (2007)', '(no genres listed)'))),\n",
       " ('156840', (0.5, ('Jurassic Attack (2012)', 'Action|Sci-Fi'))),\n",
       " ('138008', (0.5, ('New Year (2011)', '(no genres listed)'))),\n",
       " ('131152', (0.5, ('The Fat Spy (1966)', 'Comedy'))),\n",
       " ('109355', (0.5, ('13 Fighting Men (1960)', 'Western'))),\n",
       " ('127327', (0.5, ('Khan Kluay (2006)', 'Adventure|Animation|Children'))),\n",
       " ('160978', (0.5, ('Hellevator (2004)', 'Horror|Sci-Fi'))),\n",
       " ('145285', (0.5, ('Octopus (2000)', 'Action|Horror|Thriller'))),\n",
       " ('133541', (0.5, ('Two Hundred Thousand Dirty (2014)', 'Comedy'))),\n",
       " ('139717', (0.5, ('10 Cent Pistol (2015)', 'Crime|Thriller')))]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmentedRatings.takeOrdered(10, key = lambda x : x[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "- Augment the mapping process of WordCount with a function to filter out punctuations and capitalization from the unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge:\n",
    "\n",
    "1. Make appropriate changes so that only movies with averaged ratings higher than 3.75 are collected\n",
    "2. Further enhance your modification so that only movies with averaged ratings higher than 3.75 and number of ratings of at least 1000 times are collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Find genres which have the highest average ratings over the years\n",
    "\n",
    "- Identify the genres associated with a movie and its rating\n",
    "- Each movie can have multiple genres. How to flip the Key/Value pair?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('122', 2.0), ('172', 1.0), ('1221', 5.0), ('1441', 4.0), ('1609', 3.0)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieRatings.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', ('Toy Story (1995)', 'Adventure|Animation|Children|Comedy|Fantasy')),\n",
       " ('2', ('Jumanji (1995)', 'Adventure|Children|Fantasy')),\n",
       " ('3', ('Grumpier Old Men (1995)', 'Comedy|Romance')),\n",
       " ('4', ('Waiting to Exhale (1995)', 'Comedy|Drama|Romance')),\n",
       " ('5', ('Father of the Bride Part II (1995)', 'Comedy'))]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieInfo.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "augmentedInfo = movieRatings.join(movieInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1440', (3.0, ('Amos & Andrew (1993)', 'Comedy'))),\n",
       " ('1440', (2.0, ('Amos & Andrew (1993)', 'Comedy'))),\n",
       " ('1440', (3.0, ('Amos & Andrew (1993)', 'Comedy'))),\n",
       " ('1440', (5.0, ('Amos & Andrew (1993)', 'Comedy'))),\n",
       " ('1440', (3.0, ('Amos & Andrew (1993)', 'Comedy')))]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmentedInfo.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Adventure', 3.0), ('Animation', 3.0), ('Children', 3.0), ('Comedy', 3.0), ('Fantasy', 3.0)]\n"
     ]
    }
   ],
   "source": [
    "def extractGenreRating (t):\n",
    "    final_tuples = []\n",
    "    genreList = t[1][1][1].split(\"|\")\n",
    "    for genre in genreList:\n",
    "        final_tuples.append((genre,t[1][0]))\n",
    "    return final_tuples\n",
    "\n",
    "print(extractGenreRating((u'1', (3.0, (u'Toy Story (1995)', u'Adventure|Animation|Children|Comedy|Fantasy')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genreRatings = augmentedInfo.flatMap(extractGenreRating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Comedy', 3.0),\n",
       " ('Comedy', 2.0),\n",
       " ('Comedy', 3.0),\n",
       " ('Comedy', 5.0),\n",
       " ('Comedy', 3.0)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genreRatings.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge:\n",
    "\n",
    "Complete the remaining portion of task 2.2: Calculating the average rating of each genre over the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Find users who rate movies most frequently in order to contact them for in-depth marketing analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How do you define \"frequently\"?\n",
    "    - At least once per week?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userRatings = ratingsOnly.map(lambda line: (line.split(\",\")[0], float(line.split(\",\")[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('51313',\n",
       "  [847620176.0,\n",
       "   847620106.0,\n",
       "   847620374.0,\n",
       "   847620326.0,\n",
       "   847620411.0,\n",
       "   847620264.0,\n",
       "   847620347.0,\n",
       "   847619964.0,\n",
       "   847619965.0,\n",
       "   847620326.0,\n",
       "   847620233.0,\n",
       "   847620294.0,\n",
       "   847620021.0,\n",
       "   847620211.0,\n",
       "   847620021.0,\n",
       "   847620326.0,\n",
       "   847619878.0,\n",
       "   847620211.0,\n",
       "   847620264.0,\n",
       "   847620021.0,\n",
       "   847620374.0,\n",
       "   847620470.0,\n",
       "   847619923.0,\n",
       "   847620049.0,\n",
       "   847620049.0,\n",
       "   847620347.0,\n",
       "   847620411.0,\n",
       "   847620049.0,\n",
       "   847620072.0,\n",
       "   847620176.0,\n",
       "   847620211.0,\n",
       "   847620690.0,\n",
       "   847619900.0,\n",
       "   847620748.0,\n",
       "   847620748.0,\n",
       "   847620049.0,\n",
       "   847620233.0,\n",
       "   847620106.0,\n",
       "   847620656.0,\n",
       "   847620072.0,\n",
       "   847619900.0,\n",
       "   847619878.0]),\n",
       " ('23161',\n",
       "  [945058557.0,\n",
       "   945063385.0,\n",
       "   945049906.0,\n",
       "   945063316.0,\n",
       "   945049950.0,\n",
       "   945057901.0,\n",
       "   945057196.0,\n",
       "   945057745.0,\n",
       "   945057745.0,\n",
       "   945058411.0,\n",
       "   945050030.0,\n",
       "   945049753.0,\n",
       "   945063619.0,\n",
       "   945061581.0,\n",
       "   945058080.0,\n",
       "   945057505.0,\n",
       "   945057506.0,\n",
       "   945057314.0,\n",
       "   945061786.0,\n",
       "   945049117.0,\n",
       "   945057745.0,\n",
       "   945057351.0,\n",
       "   945050473.0,\n",
       "   945050180.0,\n",
       "   945063339.0,\n",
       "   945063284.0,\n",
       "   945049906.0,\n",
       "   945057821.0,\n",
       "   945062117.0,\n",
       "   945050149.0,\n",
       "   945050180.0,\n",
       "   945057977.0,\n",
       "   945057314.0,\n",
       "   945049792.0,\n",
       "   945057197.0,\n",
       "   945058302.0,\n",
       "   945309039.0,\n",
       "   945050507.0,\n",
       "   945057538.0,\n",
       "   945049986.0,\n",
       "   945057197.0,\n",
       "   945049986.0,\n",
       "   945050428.0,\n",
       "   945061591.0,\n",
       "   945058277.0,\n",
       "   945063284.0,\n",
       "   945063316.0,\n",
       "   945063511.0,\n",
       "   945050221.0,\n",
       "   945063284.0,\n",
       "   945061819.0,\n",
       "   945057453.0,\n",
       "   945061618.0,\n",
       "   945062117.0,\n",
       "   945063236.0,\n",
       "   945049906.0,\n",
       "   945057417.0,\n",
       "   945061388.0,\n",
       "   945050962.0,\n",
       "   945057745.0,\n",
       "   945061499.0,\n",
       "   945058245.0,\n",
       "   945061521.0,\n",
       "   945049237.0,\n",
       "   945050071.0,\n",
       "   945063183.0,\n",
       "   945050940.0,\n",
       "   945058495.0,\n",
       "   945049754.0,\n",
       "   945049792.0,\n",
       "   945050403.0,\n",
       "   945049792.0,\n",
       "   945050896.0,\n",
       "   945050428.0,\n",
       "   945061581.0,\n",
       "   945050453.0,\n",
       "   945050473.0,\n",
       "   945049906.0,\n",
       "   945049819.0,\n",
       "   945049723.0,\n",
       "   945049819.0,\n",
       "   945050896.0,\n",
       "   945051054.0,\n",
       "   945062059.0,\n",
       "   945050112.0,\n",
       "   945050071.0,\n",
       "   945057351.0,\n",
       "   945050221.0,\n",
       "   945063440.0,\n",
       "   945057977.0,\n",
       "   945062118.0,\n",
       "   945049861.0,\n",
       "   945057314.0,\n",
       "   945061749.0,\n",
       "   945057901.0,\n",
       "   945057868.0,\n",
       "   945061618.0,\n",
       "   945063461.0,\n",
       "   945057821.0,\n",
       "   945050030.0,\n",
       "   945058080.0,\n",
       "   945057417.0,\n",
       "   945063414.0,\n",
       "   945058080.0,\n",
       "   945050030.0,\n",
       "   945049950.0,\n",
       "   945057232.0,\n",
       "   945063385.0,\n",
       "   945061388.0,\n",
       "   945057938.0,\n",
       "   945057417.0,\n",
       "   945057506.0,\n",
       "   945057314.0,\n",
       "   945050428.0,\n",
       "   945050030.0,\n",
       "   945051070.0,\n",
       "   945057868.0,\n",
       "   945057232.0,\n",
       "   945057262.0,\n",
       "   945057262.0,\n",
       "   945049146.0,\n",
       "   945050180.0,\n",
       "   945057821.0,\n",
       "   945057197.0,\n",
       "   945057417.0,\n",
       "   945058040.0,\n",
       "   945057453.0,\n",
       "   945057506.0,\n",
       "   945050287.0,\n",
       "   945057232.0,\n",
       "   945057745.0,\n",
       "   945057417.0,\n",
       "   945063298.0,\n",
       "   945061786.0,\n",
       "   945063385.0,\n",
       "   945049754.0,\n",
       "   945063209.0,\n",
       "   945063284.0,\n",
       "   945050149.0,\n",
       "   945058006.0,\n",
       "   945050221.0,\n",
       "   945049950.0,\n",
       "   945050149.0,\n",
       "   945049646.0,\n",
       "   945049950.0,\n",
       "   945063528.0,\n",
       "   945049610.0,\n",
       "   945063339.0,\n",
       "   945050112.0,\n",
       "   945057829.0,\n",
       "   945063254.0,\n",
       "   945062118.0,\n",
       "   945049553.0,\n",
       "   945309039.0,\n",
       "   945057868.0,\n",
       "   945049861.0,\n",
       "   945049496.0,\n",
       "   945057977.0,\n",
       "   945061800.0,\n",
       "   945057314.0,\n",
       "   945049196.0,\n",
       "   945061581.0,\n",
       "   945049388.0,\n",
       "   945057262.0,\n",
       "   945049418.0,\n",
       "   945049536.0,\n",
       "   945049117.0,\n",
       "   945049449.0,\n",
       "   945063440.0,\n",
       "   945049610.0,\n",
       "   945051032.0,\n",
       "   945057453.0,\n",
       "   945049950.0,\n",
       "   945051032.0,\n",
       "   945309054.0,\n",
       "   945050112.0,\n",
       "   945057538.0,\n",
       "   945049646.0,\n",
       "   945050149.0,\n",
       "   945058557.0]),\n",
       " ('240955',\n",
       "  [861191393.0,\n",
       "   861191466.0,\n",
       "   861191466.0,\n",
       "   862840712.0,\n",
       "   862841184.0,\n",
       "   861191608.0,\n",
       "   861191394.0,\n",
       "   861191392.0,\n",
       "   861191685.0,\n",
       "   861191723.0,\n",
       "   862840951.0,\n",
       "   862840951.0,\n",
       "   861191394.0,\n",
       "   862841184.0,\n",
       "   861191524.0,\n",
       "   861191636.0,\n",
       "   862840789.0,\n",
       "   861191570.0,\n",
       "   862840431.0,\n",
       "   861191466.0,\n",
       "   861191524.0,\n",
       "   861191466.0,\n",
       "   861191466.0,\n",
       "   861191684.0,\n",
       "   861191570.0,\n",
       "   861191524.0,\n",
       "   862841383.0,\n",
       "   862840789.0,\n",
       "   861191466.0,\n",
       "   861191393.0,\n",
       "   861191684.0,\n",
       "   861191764.0,\n",
       "   861191392.0,\n",
       "   861191608.0,\n",
       "   861191524.0,\n",
       "   861191723.0,\n",
       "   861191466.0,\n",
       "   861191524.0,\n",
       "   862840293.0,\n",
       "   861191570.0,\n",
       "   862841489.0,\n",
       "   861191796.0,\n",
       "   861191832.0,\n",
       "   862841489.0,\n",
       "   861192401.0,\n",
       "   861191608.0,\n",
       "   861191685.0,\n",
       "   862841093.0,\n",
       "   861191764.0,\n",
       "   861192401.0,\n",
       "   861191861.0,\n",
       "   861191466.0,\n",
       "   862841184.0,\n",
       "   861191608.0,\n",
       "   861191570.0,\n",
       "   861191723.0]),\n",
       " ('226527', [979403411.0, 979403454.0, 979403454.0, 979403454.0, 979403411.0]),\n",
       " ('207119',\n",
       "  [1013822922.0,\n",
       "   1013822844.0,\n",
       "   1013822871.0,\n",
       "   1013822844.0,\n",
       "   1013822891.0,\n",
       "   1013822871.0,\n",
       "   1013822922.0,\n",
       "   1013822844.0,\n",
       "   1013822871.0,\n",
       "   1013822871.0,\n",
       "   1013822844.0,\n",
       "   1013822922.0,\n",
       "   1013822991.0,\n",
       "   1013823021.0,\n",
       "   1013823045.0,\n",
       "   1013823021.0,\n",
       "   1013822991.0,\n",
       "   1013823068.0,\n",
       "   1013822991.0,\n",
       "   1013823045.0,\n",
       "   1013823021.0,\n",
       "   1013822991.0,\n",
       "   1013823068.0,\n",
       "   1013823046.0,\n",
       "   1013823151.0])]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingGroupByUsers = userRatings.groupByKey().mapValues(list)\n",
    "ratingGroupByUsers.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('67056', 37.26),\n",
       " ('77986', 3230.665418227216),\n",
       " ('226527', 8.6),\n",
       " ('207119', 12.28),\n",
       " ('53196', 7.011363636363637)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgRatingFreq = ratingGroupByUsers.mapValues(lambda V: (max(V) - min(V)) / float(len(V)))\n",
    "avgRatingFreq.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [1346139060.0,\n",
    "   1346139098.0,\n",
    "   1346139113.0,\n",
    "   1346139053.0,\n",
    "   1346139234.0,\n",
    "   1346139006.0,\n",
    "   1346139209.0,\n",
    "   1346139147.0,\n",
    "   1346138998.0,\n",
    "   1346139206.0,\n",
    "   1346139224.0,\n",
    "   1346139174.0,\n",
    "   1346139152.0,\n",
    "   1346139230.0,\n",
    "   1346139181.0,\n",
    "   1346139159.0,\n",
    "   1346139314.0]\n",
    "(max(x) - min(x)) / float(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topUsers = avgRatingFreq.top(10, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('40407', 51121853.75),\n",
       " ('241087', 40917744.72727273),\n",
       " ('54838', 36601016.0),\n",
       " ('248290', 33999095.666666664),\n",
       " ('39601', 33138222.0),\n",
       " ('155302', 33013341.666666668),\n",
       " ('117995', 29406107.25),\n",
       " ('183383', 29210786.666666668),\n",
       " ('121552', 26685917.875),\n",
       " ('74936', 26309319.0)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topUsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. Airlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spark SQL**\n",
    "- Spark module for structured data processing\n",
    "- provide more information about the structure of both the data and the computation being performed for additional optimization\n",
    "- execute SQL queries written using either a basic SQL syntax or HiveQL\n",
    "\n",
    "**DataFrame**\n",
    "- distributed collection of data organized into named columns\n",
    "- conceptually equivalent to a table in a relational database or a data frame in R/Python, but with richer optimizations under the hood\n",
    "- can be constructed from a wide array of sources such as: structured data files, tables in Hive, external databases, or existing RDDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x2ba1e24c6be0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext = pyspark.SQLContext(sc)\n",
    "sqlContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airlines = sqlContext.read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .load(\"airlines/data/\")\\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 ms, sys: 2 ms, total: 9 ms\n",
      "Wall time: 1min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "123534969"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "airlines.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 ms, sys: 2 ms, total: 3 ms\n",
      "Wall time: 222 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "123534969"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "airlines.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- DepTime: string (nullable = true)\n",
      " |-- CRSDepTime: integer (nullable = true)\n",
      " |-- ArrTime: string (nullable = true)\n",
      " |-- CRSArrTime: integer (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      " |-- FlightNum: integer (nullable = true)\n",
      " |-- TailNum: string (nullable = true)\n",
      " |-- ActualElapsedTime: string (nullable = true)\n",
      " |-- CRSElapsedTime: string (nullable = true)\n",
      " |-- AirTime: string (nullable = true)\n",
      " |-- ArrDelay: string (nullable = true)\n",
      " |-- DepDelay: string (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- Distance: string (nullable = true)\n",
      " |-- TaxiIn: string (nullable = true)\n",
      " |-- TaxiOut: string (nullable = true)\n",
      " |-- Cancelled: integer (nullable = true)\n",
      " |-- CancellationCode: string (nullable = true)\n",
      " |-- Diverted: integer (nullable = true)\n",
      " |-- CarrierDelay: string (nullable = true)\n",
      " |-- WeatherDelay: string (nullable = true)\n",
      " |-- NASDelay: string (nullable = true)\n",
      " |-- SecurityDelay: string (nullable = true)\n",
      " |-- LateAircraftDelay: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airlines.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can interact with a DataFrame via SQLContext using SQL statements by registerting the DataFrame as a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airlines.registerTempTable(\"airlines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*How many unique airlines are there?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|UniqueCarrier|\n",
      "+-------------+\n",
      "|           EA|\n",
      "|           UA|\n",
      "|           PI|\n",
      "|           PS|\n",
      "|           AA|\n",
      "|           NW|\n",
      "|           EV|\n",
      "|           B6|\n",
      "|           HP|\n",
      "|           TW|\n",
      "|           DL|\n",
      "|           OO|\n",
      "|           F9|\n",
      "|           YV|\n",
      "|           TZ|\n",
      "|           US|\n",
      "|           AQ|\n",
      "|           MQ|\n",
      "|           OH|\n",
      "|           HA|\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "uniqueAirline = sqlContext.sql(\"SELECT DISTINCT UniqueCarrier \\\n",
    "                                FROM airlines\")\n",
    "uniqueAirline.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Calculate how many flights completed by each carrier over time*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+\n",
      "|UniqueCarrier|FlightCount|\n",
      "+-------------+-----------+\n",
      "|           EA|     919785|\n",
      "|           UA|   13299817|\n",
      "|           PI|     873957|\n",
      "|           PS|      83617|\n",
      "|           AA|   14984647|\n",
      "|           NW|   10292627|\n",
      "|           EV|    1697172|\n",
      "|           B6|     811341|\n",
      "|           HP|    3636682|\n",
      "|           TW|    3757747|\n",
      "|           DL|   16547870|\n",
      "|           OO|    3090853|\n",
      "|           F9|     336958|\n",
      "|           YV|     854056|\n",
      "|           TZ|     208420|\n",
      "|           US|   14075530|\n",
      "|           AQ|     154381|\n",
      "|           MQ|    3954895|\n",
      "|           OH|    1464176|\n",
      "|           HA|     274265|\n",
      "+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 2 ms, sys: 0 ns, total: 2 ms\n",
      "Wall time: 1.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "carrierFlightCount = sqlContext.sql(\"SELECT UniqueCarrier, COUNT(UniqueCarrier) AS FlightCount \\\n",
    "                                    FROM airlines GROUP BY UniqueCarrier\")\n",
    "carrierFlightCount.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*How do you display full carrier names?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carriers = sqlContext.read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .load(\"airlines/metadata/carriers.csv\")\\\n",
    "    .cache()\n",
    "carriers.registerTempTable(\"carriers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Code: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "carriers.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+-----------+\n",
      "|         Description|UniqueCarrier|FlightCount|\n",
      "+--------------------+-------------+-----------+\n",
      "|Pinnacle Airlines...|           9E|     521059|\n",
      "|American Airlines...|           AA|   14984647|\n",
      "| Aloha Airlines Inc.|           AQ|     154381|\n",
      "|Alaska Airlines Inc.|           AS|    2878021|\n",
      "|     JetBlue Airways|           B6|     811341|\n",
      "|Continental Air L...|           CO|    8145788|\n",
      "|    Independence Air|           DH|     693047|\n",
      "|Delta Air Lines Inc.|           DL|   16547870|\n",
      "|Eastern Air Lines...|           EA|     919785|\n",
      "|Atlantic Southeas...|           EV|    1697172|\n",
      "|Frontier Airlines...|           F9|     336958|\n",
      "|AirTran Airways C...|           FL|    1265138|\n",
      "|Hawaiian Airlines...|           HA|     274265|\n",
      "|America West Airl...|           HP|    3636682|\n",
      "|Midway Airlines I...|       ML (1)|      70622|\n",
      "|American Eagle Ai...|           MQ|    3954895|\n",
      "|Northwest Airline...|           NW|   10292627|\n",
      "|         Comair Inc.|           OH|    1464176|\n",
      "|Skywest Airlines ...|           OO|    3090853|\n",
      "|Pan American Worl...|       PA (1)|     316167|\n",
      "+--------------------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 9 ms, sys: 1 ms, total: 10 ms\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "carrierFlightCountFullName = sqlContext.sql(\"SELECT c.Description, a.UniqueCarrier, COUNT(a.UniqueCarrier) AS FlightCount \\\n",
    "                                    FROM airlines AS a \\\n",
    "                                    INNER JOIN carriers AS c \\\n",
    "                                    ON c.Code = a.UniqueCarrier \\\n",
    "                                    GROUP BY a.UniqueCarrier, c.Description \\\n",
    "                                    ORDER BY a.UniqueCarrier\")\n",
    "carrierFlightCountFullName.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What is the averaged departure delay time for each airline?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+---------------------------+-------------------+\n",
      "|first(Description, false)|first(UniqueCarrier, false)|        AvgDepDelay|\n",
      "+-------------------------+---------------------------+-------------------+\n",
      "|     Pinnacle Airlines...|                         9E| 7.9279144892173035|\n",
      "|     American Airlines...|                         AA|  7.862321254420546|\n",
      "|      Aloha Airlines Inc.|                         AQ| 1.5993176899118409|\n",
      "|     Alaska Airlines Inc.|                         AS|  8.297235193754096|\n",
      "|          JetBlue Airways|                         B6| 11.262714178314551|\n",
      "|     Continental Air L...|                         CO|  7.695967155526857|\n",
      "|         Independence Air|                         DH|  9.612639389688926|\n",
      "|     Delta Air Lines Inc.|                         DL|  7.593716274369933|\n",
      "|     Eastern Air Lines...|                         EA|  8.674050565435543|\n",
      "|     Atlantic Southeas...|                         EV| 13.483736343326541|\n",
      "|     Frontier Airlines...|                         F9|  6.096932123645889|\n",
      "|     AirTran Airways C...|                         FL|  10.27801937883596|\n",
      "|     Hawaiian Airlines...|                         HA|-0.5165400834606493|\n",
      "|     America West Airl...|                         HP|  8.107790266585615|\n",
      "|     Midway Airlines I...|                     ML (1)|  6.229676674364896|\n",
      "|     American Eagle Ai...|                         MQ|   9.22369994420141|\n",
      "|     Northwest Airline...|                         NW|  6.007973703240084|\n",
      "|              Comair Inc.|                         OH|  9.310795113723774|\n",
      "|     Skywest Airlines ...|                         OO|  7.193778047766392|\n",
      "|     Pan American Worl...|                     PA (1)|  5.532442442890681|\n",
      "+-------------------------+---------------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 999 µs, sys: 2 ms, total: 3 ms\n",
      "Wall time: 6.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "avgDepartureDelay = sqlContext.sql(\"SELECT FIRST(c.Description), FIRST(a.UniqueCarrier), AVG(a.DepDelay) AS AvgDepDelay \\\n",
    "                                    FROM airlines AS a \\\n",
    "                                    INNER JOIN carriers AS c \\\n",
    "                                    ON c.Code = a.UniqueCarrier \\\n",
    "                                    GROUP BY a.UniqueCarrier \\\n",
    "                                    ORDER BY a.UniqueCarrier\")\n",
    "avgDepartureDelay.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airlines.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
